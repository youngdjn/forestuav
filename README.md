This is a collection of scripts for evaluating how different drone imagery collection and processing parameters influence the quality of automatically generated tree maps.

## Workflow
1) **Collect drone imagery from the study site** with multiple missions with different mission parameters (e.g., flight altitude, gimbal angle). Fly each mission at high image overlap so that photosets can be thinned later to evaluate the influence of image overlap. The flight mission parameters used to acquire each photo set are recorded in `{data}/parameter_set_definitions/imagery-collection-log.csv`.
3) **Thin mission photosets** by selecting every *i*th photo in every *j*th transect (done by `scripts/thin_drone_photoset.R`). Thinned photosets are in `{data}/drone_image_sets_thinned/`. The nomenclature for the thinned photo sets is "setnumber_thin##", where the two thinning numbers, in order, are the forward thinning factor and the side thinning factor. For example, "set14_thin24" is photo set 14 thinned by a factor of 2 in the forward direction and a factor of 4 in the side direction.
4) **Create composite photosets** by combininng photo sets that have already been thinned (e.g., a nadir and oblique photo set). The individual photo sets used to create each composite photo set are recorded in `{data}/parameter_set_definitions/imagery-collection-log.csv`. Composite photo sets have a four-digit thinning code. The first two numbers are the forward thinning factors of the two contributing photo sets (in the order specified in `{data}/parameter_set_definitions/imagery-collection-log.csv`, and the second two numbers are the side thinning factors of the two photo sets.
5) **Prepare photo sets for photogrammetric processing** by adding GCP and DEM data into the root folder of each photo set as specified in the documentation of the [UC Davis Metashape scripts](https://github.com/ucdavis/metashape).
6) **Photogrammetrically process each thinned photoset in Metashape** to produce a digital surface model (DSM) and point cloud using different sets of Metashape parameters. Definitions of the flight and processig parameters associated with each set of Metashape outputs are in `{data}/parameter_set_definitions/photoset-processing-params.csv`. The photoset thinning codes specified in that file coorespond to the photoset naming conventions as described in **Thin mission photosets* and **Create composite photosets** above. Metashape is run using the [UC Davis Metashape scripts](https://github.com/ucdavis/metashape). This workflow involves using detailed YAML configuration files for each Metashape run to document the processing parameters and enable reproduction. The configuration files used are in `{data}/metashape_configs`. Runs were performed using [v0.1.0](https://github.com/ucdavis/metashape/releases/tag/v0.1.0) of the scripts. [This step is performed on a GPU machine.]
7) **Post-process the photogrammetric products** by cropping the DSM to the focal area, normalizing by subtracting the terrain elevation (from a USGS DEM) to yield a canopy height model, and upscaling it to a 0.12 m resolution (done by `scripts/crop_and_noralize_dsm.R`); and by cropping the point cloud to the focal area, decimating it to 50 pts per sq m, and normalizing it by subtracting the terrain elevation (done by `scripts/crop_and_thin_las.R`). The normalization approach we use is reasonable because the UC Davis Metashape scripts GCP workflow ties the drone imagery elevation to the USGS DEM elevation, and only GCPs at or very close to bare ground are used. The resulting products are in `{data}/metashape_outputs_postprocessed/`. For the CHMs, the naming convention is {photo set}\_{processing parameters}\_{Metashape processed date-time}\_{layer type}. The processing parameters value is composed of four or five digits. The final two digits correspond to the metashape processing parameter set (defined in `{data}/parameter_set_definitions/photoset-processing-params.csv`). The initial one or two digits (following the "1" that precedes all values) indicates the photoset thinning factors used (also as defined in `{data}/parameter_set_definitions/photoset-processing-params.csv`). For the point clouds, the naming convention is the same except there is not a preceding "1". [This step is performed on the GPU machine.]
9) **Process the canopy height model and point clouds into maps of estimated tree locations** using different tree detection algorithms. Scripts for this step are in `scripts/tree_detection`. The tree detection scripts use the tree detection methods and their parameterizations as described in `{data}/parameter_set_definitions/vwfdefs_fullrange.csv` and `{data}/parameter_set_definitions/best_las.csv`. [This computationally intensive step is performed on a HPC cluster.]
10) **Generate a ground-truth map of tree locations** from a ground-based survey of the study area. The ground-based plot data are converted to a spatial map of tree locations by `scripts/ground_survey_to_spatial.R`. The ground survey plot locations recorded by GPS may be inaccurate, so for the purposes of stem map creation, the plot locations are manually placed into more appropriate locations based on the knowledge that they composed a square grid with regular spacing (corrected plot centers: `{data}/ground_truth/interpreted/plots_manuallyCorrectedComplete.geojson`). Some spatial error in plot locations remains, so the next step is to compare the resulting stem map against an initial "referene" drone-derived stem map (`{data}/reference_drone_stem_map/treetops_vwf001.geojson`) and manually shift the ground-survey locations of the trees trees that are clearly apparent in both the drone-based and ground-based stem map, compute summaries of the shifts by plot to get an optimal amount by which to spatially shift each plot (done by `scripts/check_ground_survey_rectification.R`, yielding `{data}/reference_alignment_eval/tree_shift_dir_summary.csv`), then shift all trees referenced from each plot center based on the optimal shift determined for each plot center (performend by `scripts/rectify_ground_survey.R`, yielding `{data}/ground_truth_stem_map/rectified/ept_trees_01_rectified.geojson`). Finally, ground-truth trees are classified as "dominant" or "not dominant" based on their height and position relative to neighbors (performed by `scripts/ground_stem_map_detect_under_neighbors.R`, which updates the rectified stem map data file).
12) **Compare the drone-derived stem maps to the ground-truth stem map** (TO DO).

**Data:** Data are stored on Box at https://ucdavis.box.com/s/yxgngz750ommo73kz5akeac0q7ci5wgi (contact me for access). The top of every data-dependent script includes a line that can be changed to point to the top level of the data directory in your file system (e.g., via Box Drive). All data references within the scripts are appended to that top-level data directory path.
